<div align="center">
  <h1>
    WebServer
  </h1>
</div>

## moduo-buffer

`moduo-buffer`采用的是非阻塞`I/O`模型，每次`send()`不需要一次发完，将没发完的数据存在`stackbuff` 中，对`buffer`实现动态增长，防止`buffer`数组最初过大，从而占据较多的内存

## 智能指针

智能指针可以在适当的时机自动释放分配的内存，使用智能指针可以很好的避免忘记释放内存而导致的内存泄露问题

> C++ 智能指针底层是采用引用计数的方式实现的。简单的理解，智能指针在申请堆内存空间的同时，会为其配备一个整形值（初始值为 1），每当有新对象使用此堆内存时，该整形值 +1；反之，每当使用此堆内存的对象被释放时，该整形值减 1。当堆空间对应的整形值为 0 时，即表明不再有对象使用它，该堆空间就会被释放掉。

### 独占式`unique_ptr`

使用`move()`给`unique_ptr`传入函数,这样你就知道原先的`unique_ptr`已经失效了，但是对于`move`之后使用原来的内容是未定义行为,

1. 为动态申请的内存提供异常安全
2. 将动态申请的内存所有权传递 move() 给某函数
3. 从某个函数返回 move() 动态申请内存的所有权
4. 在容器内保存指针
5. **无法进行复制构造**，**无法进行复制赋值操作**，但是可以进行**移动构造**和移动赋值操作
6. auto_ptr 拥有的功能

move(xxx) 之后 xxx会被释放成 null，unique_ptr 是通过指针**占有**并**管理**另一个对象，并在 unique_ptr 离开作用域时释放该对象的智能指针，某个时刻，**只能有一个** unique_ptr 指向一个给定的对象

```cpp
vector<unique_ptr<int>> arr;
unique_ptr<int> p(new int(3));
arr.push_back(move(p));//不能直接 push_back
```

### 共享式`shared_ptr`

多个 shared_ptr 可以共同使用同一块堆内存 ，底层也是采用的引用计数机制，只有当引用技术为 0，堆内存才会被释放

```cpp
//shared_ptr 类型的空智能指针，注意，空的shared_ptr 指针，其初始引用计数为0，而不是1
shared_ptr<int> p1;
shared_ptr<int> p2(nullptr);
//直接明确指向
shared_ptr<int> p3(new int(10));
shared_ptr<int> p4 = make_shared<int>(10);
```

`shared_ptr` 提供有相应的拷贝构造和移动构造函数

```cpp
//拷贝构造函数
shared_ptr<int> p5(p4);// shared_ptr<int> p5 = p4;
//移动构造
shared_ptr<int> p6(move(p5));//shared_ptr<int> p6 = move(p5);
```

> 对于 move(p4) 来说，该函数会强制将 p4 转换成对应的右值，因此初始化 p5 调用的是移动构造函数。另外和调用拷贝构造函数不同，用 move(p4) 初始化 p5，会使得 p5 拥有了 p4 的堆内存，而 p4 则变成了空智能指针。

**注意** ： 同一普通指针不能同时为多个 shared_ptr  对象赋值，否则会导致程序异常

shared_ptr 在初始化时可以自定义所指堆内存的释放规则

```cpp
shared_ptr<int> p1(new int[10],default_delete<int[]>()); //指定default——delete作为释放规则
void deleteIne(int *p) {//自定义释放规则
  delete []p;
}
shared_ptr<int> p2(new int[10],deleteInt);
shared_ptr<int> p3(new int[10],[](int *p){delete []p;});
```

![shared_ptr<T>.png](./WebServer.assets/shared_ptr.png)

### 弱式`weak_ptr`

> 当 weak_ptr 类型指针的指向和某一 shared_ptr 指针相同时，weak_ptr 指针并不会使所指堆内存的引用计数加 1；同样，当 weak_ptr 指针被释放时，之前所指堆内存的引用计数也不会因此而减 1。也就是说，weak_ptr 类型指针并不会影响所指堆内存空间的引用计数。
>
> 除此之外，weak_ptr 模板类中没有重载 * 和 -> 运算符，这也就意味着，weak_ptr 类型指针只能访问所指的堆内存，而无法修改它。

![weak_ptr.png](./WebServer.assets/weak_ptr.png)

## function 函数

### 实例

和直接调用函数的本质区别  -- 是否需要在运行时动态 “持有”并 ”调度“ 不同的可调用体

可以存储任何可调用对象，包括函数指针、函数对象、成员函数指针和lambda表达式。

```cpp
function<return_type(parameter_types)> var_name;
function<void(int)> func;//表示 func 可以接收任意 void() 类型的函数返回，例如 void foo()
```

其中，`return_type` 是函数返回值类型，`parameter_types` 是函数参数类型

```cpp
int func(int x,int y) {return x + y;}
function<int(int,int)> f = func;
class A {
  public:
  int mem_func(int x){return x * x};
};
function<int(A*,int)> f2 = &A::mem_func;
```

function 对象可以向普通函数一样调用，并且可以使用 bool 类型的运算符来检查调用对象是否为空

```cpp
function<int(int,int)> f;
if(f)
  	cout << f(1,2) << endl;
else cout << "f is empty" << endl;
```

具体使用例子

```cpp
void test1() {
    cout << "function" << endl;
}
int test2(int i) {
    return i;
}
int test3(int i, int j) {
    return i + j;
}
struct A {
    void foo(int i) {
        cout << i << endl;
    }
};

int main() {
    // 1. 绑定无参函数 test1
    function<void()> fn1 = bind(test1);
    // 2. 绑定一参函数 test2，但声明为 function<int(int,int)>
    function<int(int,int)> fn2 = bind(test2, placeholders::_1);
    // 3. 绑定二参函数 test3，对应同样接受两个参数的 function
    function<int(int,int)> fn3 = bind(test3, placeholders::_1, placeholders::_2);
    // 4. “预置” test3 的第一个参数为常量 3，仅剩下一个占位符
    function<int(int)> fn4 = bind(test3, 3, placeholders::_1);
    // 5. test3 的两个参数都用常量“固化”了，此时生成可无参调用的可调用对象
    function<int()> fn5 = bind(test3, 3, 4);
    A a;
    // 6. 绑定成员函数 A::foo，将 this 指针设为 &a
    function<void(int)> fn6 = bind(&A::foo, &a, placeholders::_1);
  	fn1();
    cout<<fn2(1)<<endl;
    cout<<fn3(2, 3)<<endl;
    cout<<fn4(3)<<endl;
    cout<<fn5()<<endl;

}
```

> C++ 中 `bind` 返回的可调用对象有一个**通用的模板式 `operator()`**，它可以接受“匹配到所需占位符”之外的额外参数，并将它们“丢弃”。也即 fn2(x,y) = test2(x) , 	(y 会被丢弃)
>
> bind(&A::foo,&a,placeholder::_)  隐式地第一个参数是该方法所属对象的指针（俗称 `this` 指针），第二个参数是 `int i`。
>
> fn6(x) = a.foo(x)

### function 的好处

`function<R(Args...)>` 可以封装几乎所有“可调用”的实体，包括：

- 普通函数指针（`void foo(int)`）；
- 成员函数指针（`&MyClass::method`，配合对象指针或引用调用）；
- Lambda 表达式（捕获外部变量的匿名函数）；
- 仿函数（重载了 `operator()` 的类）；
- 另外一层 `bind` 或 `function` 本身生成的可调用对象。

`function` 内部采用类型擦除技术，把不同类型的可调用对象都包装成同一种“虚拟接口”，即 `operator()(Args...) → R`。这样调用方只需知道“它能被调用且返回 R”，无需关心它背后是哪个具体类型。

所以使用 function 函数作为参数时，用户自定义这类参数传入时就会有很大的方便性，比较使用于**回调机制**

**通过 `function` 先存储再调用**

- **绑定方式**：运行时绑定（类型擦除 + 小对象或堆内存存储 + 间接调用）。
- **性能**：比直接调用多一次间接跳转，还可能有堆分配开销。
- **优势**：
	1. 可以在运行时动态改变目标函数／Lambda／成员函数／函数对象；
	2. 同一接口先后接受多种可调用类型，使用者无需编写单独的重载或模板；
	3. 常用于回调、事件分发、策略注入、线程池任务提交等场景。

### 进阶

#### 与智能指针结合

`function` 可以存储指针指针，避免内存泄漏

```cpp
function<int(int,int)> add = make_shared<int(*)(int,int)> ([](int a,int b)) {return a + b};
```

#### 存储成员函数指针

```cpp
class A {
  int add(int a,int b) {return a + b;}
};
function<int(A&,int ,int)> add = &A::add;
A a;
cout << add(a,3,4) << endl;
```

#### 存储 bind

```cpp
function<int(int)> add = bind([](int a,int b) { return a + b;},3,palceholders::_1);
```

## Tempalte

### 函数模板声明

1. 一个**非模板函数**可以和一个同名的**函数模板**同时存在，而且该函数模板还可以被实例化为这个非模板函数
2. 对于非模板函数和同名函数模板，如果其他条件都相同，在调动时会优先调用非模板函数而不会从该模板产生一个实例。如果模板可以产生一个具有更好匹配的函数，那么将选择模板。

#### 函数定义

```cpp
template<typename T>
void swap(const T*a,const T*b) {
  T temp = *a;
  *a = *b;
  *b = temp;
}
```

传入不同的参数时其实调用的是不同的函数，**根据不同的类型通过模板定制出专属该类型的函数，然后在调用，不同的参数对应不同的地址**

#### 函数模板调用

隐式调用，自动匹配传入参数的类型

```cpp
int main() {
  int a = 10,b = 20;
  float c = 30,d = 40;
  swap(&a,&b);
  swap(&c,&d);
}
```

#### inline 函数模板

```cpp
template<typename T>inline T swap(const T*a,const T*b) // 注意 inline 在 template 后面
```

### 类模板

类模板实例化和函数模板实例化不同，类模板实例化需要在类模板名字后跟 `<>`，然后将实例化的类型放在 `<>` 中，**类模板名字不是真正的类，而实例化的结果才是真正的类** 。

#### 类模板声明

```cpp
template<class Type>class Queue{
public:
    Queue();
    Type &front();
    const Type &front()const;
    void push(const Type &);
    void pop();
    bool empty()const
private:
    ...
};
```

#### 类模板定义

**注意 ：** 和函数模板不同，类模板的定义需要加个括号(显式)告诉编译器是什么类型

```cpp
queue<int>qi;//什么是显式，在定义时加个括号告诉他老子是int就是显式
Queue<vector<double>>qc;
Queue<string>qs;
```

### 非类模板形参

### 模板特化



## Channel

对 `fd`事件的封装，包括注册它的事件以及回调。

- events_ ： Channel 在当前 EventLoop 中注册给 poller(epoll) 时所表明的**感兴趣事件掩码(mask)**，如EPOLLIN、EPOLLOUT。决定了下次调用 `epoll_ctl(EPOLL_CTL_MOD/ADD)`时要想内核注册的监听事件
- revents_:   Poller 返回时告诉 Channel ，哪些事件已经就绪，通常在`HandleEvents()`被调用时被赋值为 epoll_wait 返回的就绪事件位。

当遇到 挂起(EPOLLHUP) 或者错误(EPOLLERR)时，前者是**对端已经关闭了连接**，此时 poller 不需要在监听这个 fd

### events_置为 0

既表明“我已经不再关心任何 I/O 事件”，下次如果上层逻辑仍打算对这个 Channel 再做处理（如重启、重连），就会显式调用 `Channel::EnableReading()`、`EnableWriting()` 等去重新将 `events_` 恢复成具体的 EPOLLIN/EPOLLOUT，再通过 `Update()` 向 epoll 注册。

如果上层准备彻底关闭这个 Channel，就会在 `events_ == 0` 的基础上调用 `RemoveChannel()`，彻底把文件描述符从 epoll 中移除并关闭。

当检测到 `EPOLLHUP`（没有可读挂起）或 `EPOLLERR`（出错）时，说明该 Channel 所对应的 fd 已经不可再进行正常 I/O，必须**立即停止向 epoll 注册任何事件**，以避免下一轮再次收到相同错误/挂起通知。

### read

**EPOLLIN：普通可读事件**

​	表示**有数据可读**（通常是对端发来了正常的应用数据）。

​	一旦出现，就需要调用 `HandleRead()` 去把缓冲区里的数据一次性读完并交给业务逻辑处理。

**EPOLLPRI：高优先级（OOB）数据**

​	对于 TCP 套接字，如果对端通过 `send(..., MSG_OOB)` 发送了“紧急数据”（Out‐Of‐Band data），内核会在相应的文件描述符上产生 `EPOLLPRI`。

​	这类数据往往是“特殊标记”或“单字节告警”，需要跟普通可读（`EPOLLIN`）分开处理。

​	把它跟 `EPOLLIN` 一起检查，意味着：无论是普通数据还是 OOB 数据到来，都由 `HandleRead()` 决定“究竟先读普通、先读 OOB”或“分别调用不同处理逻辑”。

**EPOLLRDHUP：对端关闭（半关闭）通知**

​	该标志专门用于表示“TCP 对端已经调用了 `close()` 或者只关闭了写端（shut down write）”。

​	当对端半关闭时，内核会给本端返回一个“可读”且带 `EPOLLRDHUP` 的事件。此时如果不读取，就会漏掉“对端已经发来的最后那一批数据＋一个 EOF”信号。

在收到 `EPOLLRDHUP` 时，即使没有新数据 `EPOLLIN`，也应当调用 `HandleRead()`，让它执行两件事：

1. **把剩余数据全部读干净**（因为对端在半关闭前可能还有缓冲数据）；
2. **检测到读取到 0 字节**，从而确认对端已真正关闭，便可以走“清理 Channel／关闭 socket”逻辑。

## Poller

`Poller` 类的作⽤就是负责监听⽂件描述符事件是否触发以及返回发⽣事件的⽂件描述符以及具体事件。所以⼀个Poller 对象对应⼀个 IO 多路复⽤模块。在 `muduo` 中，⼀个 `EventLoop` 对应⼀个 `Poller`。

`reinterpret_cast`⽤在任意指针(或引⽤)类型之间的转换

## 内存池

内存分配方式，`new、malloc`方式申请分配内存时由于所申请内存块的大小不定，当频繁使用时会造成大量的**内存碎片**并进而降低性能。

内存池这是在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块，若内存块不够在继续申请新的内存。

**主要管理工作**：对于内存块中空闲存储单位的管理

### 池化技术

特征降维方法；作用是在保留图像或特征图中最显著信息的同时减少数据量，从而提高计算效率并防止过拟合。

#### 最大池化

在每个区域内选择最大值作为输出值。这样可以保留局部区域内的最显著特征，丢弃次要信息。它具有平移不变性，在一定程度上提高了模型对位置变化的鲁棒性。

#### 平均池化

在每个区域内计算平均值作为输出值。这种方式可以对整个区域进行平均，从而得到更加全局的统计信息，适用于一些需要考虑整体趋势而不仅仅关注局部细节的任务。

### 内存碎片

内存碎片是指已分配的内存空间中存在的一些零散、不连续的小块未被使用的内存

1. **外部碎片**：即由于已分配内存块的释放而造成的未被充分利用的空闲内存块。这些空闲块虽然总大小足够，但由于彼此之间存在占用的块，无法组合成足够大的连续空闲区域。
2. **内部碎片**：即已分配给进程或应用程序的内存中，实际使用但没有被完全填满的部分。例如，某个进程申请了100个字节的内存，但只实际使用了80个字节，那么剩下的20个字节就构成了一个内部碎片。

#### 如何解决内存碎皮

1. 碎片整理（Defragmentation）：通过将已分配和未分配的内存重新组织排列来减少外部碎片。这通常需要暂停程序运行并进行较大规模数据搬移操作。
2. 分区策略优化：根据程序的内存使用特点，合理划分内存分区，减少外部碎片产生的可能性。例如采用动态分区或伙伴系统等算法。
3. 内存池管理：提前申请一块较大的内存空间，并自行管理内部碎片和对象的分配与释放，减少频繁的内存申请和释放操作。
4. 垃圾回收机制：对于某些编程语言如Java、Python等，利用垃圾回收器自动清理不再使用的对象，可以有效减少内部碎片。

## webbench

先在主进程中 fork 出多个⼦进程，每个⼦进程都循环做 web 访问测试。⼦进程把访问的结果通过pipe(管道)告诉⽗进程，⽗进程做最终的统计结果。webbench 最多可以模拟3万个并发连接去测试⽹站的负载能⼒。

## 零拷贝技术

拷贝是指计算机中的 I/O 操作，也就是数据的读写操作。

> 1. 应用程序先发起读操作，准备读取数据了；
> 2. 内核将数据从硬盘或外部存储读取到内核缓冲区；
> 3. 内核将数据从内核缓冲区拷贝到用户缓冲区；
> 4. 应用程序读取用户缓冲区的数据进行处理加工；



![零拷贝.png](./WebServer.assets/%E9%9B%B6%E6%8B%B7%E8%B4%9D.png)

#### 内核态

1. 内核态是操作系统内核运行的模式，当操作系统内核执行特权指令时，处于内核态
2. 在内核态下，操作系统内核拥有最高权限，可以访问计算机的所有硬件资源和敏感数据，执行特权指令，控制操作系统的整体运行
3. 内核态提供了操作系统管理和控制计算机硬件的能力，它负责处理系统调用、中断、硬件异常等核心任务。

#### 用户态

这里的用户可以理解为应用程序，这个用户是对于计算机的内核而言的，对于内核来说，系统上的各种应用程序会发出指令来调用内核的资源，这时，应用程序就是内核的用户。

1. 用户态是应用程序运行的模式，当应用程序执行普通的指令时，处于用户态
2. 在用户态下，应用程序只能访问自己的内存空间和受限的硬件资源，无法直接访问操作系统的敏感数据或控制计算机的硬件设备
3. 用户态提供了一种安全的运行环境，确保应用程序之间相互隔离，防止恶意程序对系统造成影响。

### 内核缓冲区

内存中专门用来给内核直接使用的内存空间，应用程序和外部存储进行数据交互的一个中间介质。

### 用户缓冲区

应用程序可以直接读写的内存空间。应用程序无法直接到内核读写数据，所以应用程序想要处理数据，必须先通过用户缓冲区。

### PageCache

1. PageCache Linux内核对文件系统进行缓存的一种机制，使用空闲内存才能来缓存从文件系统读取的数据块，加速文件的读取和写入操作
2. 当应用程序或进程读取文件时，数据会首先从文件系统读取到 PageCache 中，如果后续继续读取相同的数据，就可以直接从 PageCache 中获取，避免再次访问文件系统
3. 同样，当应用程序或进程将数据写入文件时，数据会暂存到 PageCache 中，然后由 Linux 内核异步的将数据写入磁盘，从而提高写入操作的效率。

### 磁盘缓冲区

计算机内存中用于暂存从磁盘读取的数据或将数据写入磁盘之前的临时存储区域，他是一种优化磁盘 I/O 操作的机制，通过利用内存的快速访问速度，减少对慢速磁盘的频繁访问，提高数据读取和写入的性能和效率。

![用户态-内核态.png](./WebServer.assets/%E7%94%A8%E6%88%B7%E6%80%81-%E5%86%85%E6%A0%B8%E6%80%81.png)

### 问题

数据的传输通常设计多次**数据拷贝**，数据需要从应用程序的用户缓冲区复制到内核缓冲区，然后在从内核缓冲区复制到设备或网络缓冲区，导致多次内存访问和数据复制，消耗大量的 CPU 时间和内存带宽。

由于数据要经过内核缓冲区，导致数据在**用户态和内核态之间来回切换**，切换过程中有上下文的切换，增加了复杂性和时间开销

### 零拷贝

思路：减少拷贝次数，尽量将数据存储在离应用程序(用户缓冲区)近的地方

理想状态：操作数据不用拷贝，实际是尽量减少拷贝操作的次数

1. 尽量减少数据在各个存储区域的复制操作，例如从磁盘缓冲区到内核缓冲区
2. 尽量减少用户态和内核态的切换次数和上下文切换
3. 使用一些优化手段，例如 PageCache

### 实现

#### 直接内存访问 (DMA)

![直接访问内存-DMA.png](./WebServer.assets/%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE%E5%86%85%E5%AD%98-DMA.png)

DMA 是一种硬件特性，允许外设直接访问系统内存，而**无需 CPU 的介入**，在数据传输时，DMA可以直接将数据从内存传输到外设，或从外设传输数据到内存，避免数据在用户态和内核态之间的多次拷贝

#### sendfile

系统调用，在网络传输文件时实现零拷贝，应用程序可直接将文件数据从文件系统传输到网络套接字或者目标文件，而无需经过用户缓冲区和内核缓冲区

#### 共享技术

![共享技术.png](./WebServer.assets/%E5%85%B1%E4%BA%AB%E6%8A%80%E6%9C%AF.png)

通过共享一块内存区域，实现数据的共享，类似于引用对象，实际就是一个指针，一个地址

#### 内存映射文件

**直接将磁盘文件映射到应用程序的地址空间**，应用程序可以直接在内存中读取和写入数据。**映射文件内容**

当数据文件需要传输时，内核可以直接从内存映射区域读取数据进行传输，避免了数据在用户态和内核态之间的额外拷贝



## problem

### IO 多路复用是同步还是异步？

1. **IO 多路复用（I/O Multiplexing）本质上属于“同步 IO”的一类**

	所谓 **同步 IO**（Synchronous I/O），指的是 **发起一次 IO 操作后，该线程会阻塞在系统调用里，直到某个条件满足才返回。**

	对于 select/poll/epoll 这类“IO 多路复用”机制，应用通常这么做：

	```cpp
	int nready = epoll_wait(epoll_fd, ready_list, max_events, timeout);
	```

	这行调用本身就是“同步”的：当内核中没有任何感兴趣的 FD 就绪时，调用会一直阻塞（或直到 timeout 到达）才会返回。

	当有若干描述符满足可读、可写或异常时，`epoll_wait` 才会“同步地”把就绪列表返回给用户态，并让后续代码逐个对这些就绪 FD 做读/写。

2. **为什么说它是同步？**

	**调用时刻：** 发起 `epoll_wait()` 时，线程进入内核态并挂起，等到内核检测到某个 socket 状态改变（可读/可写/异常），才让线程恢复；期间调用者一直在“等”。

	**处理方式：** 当 `epoll_wait` 返回后，应用才能对具体的文件描述符执行 `read()`/`write()`。这时，同步地读取或写入数据，整个流程从“检查就绪”到“真正读写”都在同一个线程上下文里按顺序完成。

3. **与真正的“异步 IO”区分**

	“异步 IO”（Asynchronous I/O）则是指：应用向内核提交一次读或写请求后，**立刻就能得到返回（不会阻塞）**，后续内核在完成底层操作后会以某种方式（信号、回调、轮询、事件通知等）告知应用“数据已经就绪，可以取走”或者“写入已经完成”。

	POSIX AIO（`aio_read`/`aio_write`）或 Linux 的 io_uring 就允许内核在后台真正独立地完成磁盘读写、网络收发等，应用可以在完全不阻塞的情况下同时发出多个 IO 请求，然后再去“查询”或者“回调”获取结果。

总结：**select/poll/epoll 这一类 IO 多路复用，属于“同步 IO”范畴**——它让调用线程在 `epoll_wait` 阻塞，直到内核告知有 FD 就绪后，才切换到“逐个处理”那些就绪 FD 的同步读写操作。

------

### 同步 IO 与异步 IO 的主要区别

| 维度           | 同步 IO（Blocking/Synchronous）                              | 异步 IO（Non‐Blocking/Asynchronous）                         |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **调用行为**   | 发起一次系统调用后，线程会阻塞直到操作完成或就绪事件到达     | 发起请求后立即返回，应用无需等待；内核会在后台完成 IO，并通过信号/回调等通知应用 |
| **资源占用**   | 阻塞期间线程无法做其他事情                                   | 同一线程可同时发起多个请求，减少上下文切换；内核负责后续处理并通知 |
| **易用性**     | 编程模型直观：先“等”再“做”；逻辑流程简单                     | 编码复杂：需要管理申请队列、完成队列、回调/回显、状态检查等，业务逻辑会更分散 |
| **性能与场景** | 适合连接数不多或对延迟不敏感的场合；通过 poll/epoll 可以复用一个线程处理多连接1 | 适合对延迟要求极高、IO 操作本身开销大（如大量磁盘访问）的场景；可避免线程阻塞 |
| **典型实现**   | `read()`/`write()`、`select()`/`poll()`/`epoll_wait()` 等同步调用 | Linux AIO（`io_submit`/`io_getevents`）、io_uring、Windows 的 Overlapped IO 等 |

> 1. 通过 IO 多路复用，虽然本质仍是“同步读写”，但一个线程可同时“等多个 FD”并在它们就绪后分别调用同步 `read`/`write`，从而实现“伪并发”。
> 2. 真正的异步 IO（Kernel AIO、io_uring）会让“读写操作”也在内核态异步完成，用户态无需再同步调用 `read`/`write`，而只需等待“完成事件”。

------

### 项目中为何更常使用 IO 多路复用而非异步 IO

1. **使用成本与跨平台兼容性**

	**API 复杂度**：

	以 Linux AIO 为例，申请和获取完成事件时需要填写 `iocb`、维护 `io_context`，还要处理“异步完成队列”（`io_getevents`／回调式）。io_uring 尽管简化了许多，但依然需要学习一套专门的接口，并处理提交队列、完成队列、Ring Buffer 的 mmap 等。

	相比之下，`epoll`/`poll`/`select` 等已在几乎所有类 UNIX 系统、主流 C++ 网络框架中成熟封装，使用门槛低。

	**可移植性**：

	- 异步 IO（POSIX AIO、io_uring）在不同 Linux 发行版、内核版本上的支持度不一；部分老内核对 io_uring 支持有限。
	- Windows 也有自己的 IOCP、Overlapped IO，但与 Linux AIO/epoll 差异较大。若需要跨平台（Linux、BSD、macOS、Windows），使用统一的“同步 IO + 多路复用”模型更易移植。

2. **网络 IO 场景下异步 IO 并不常用**

	**Linux AIO 主要针对磁盘文件 IO**：

	- 早期 Linux AIO（基于 POSIX AIO）对网络套接字并不友好，主要优化磁盘块读写、数据库场景下的大文件并发读写。网络 socket 的异步提交在很多发行版里并未得到良好支持。
	- `io_uring` 虽然已经能够支持 socket 异步收发，但它的学习曲线和集成成本都较高。

	- **网络延迟与系统调用开销**：
		- 一次 `send()` 或 `recv()` 的系统调用延迟相对较小，短时间就绪后返回；与磁盘 I/O 需要等待机械臂移动、磁盘寻道相比，网络读写的阻塞时长通常较低。
		- 因此，通过 `epoll` 监听大量并发连接，并在它们可读/可写时同步调用 `read/write`，在大多数网络服务器场景中已足够高效。

3. **编程模型与业务逻辑的清晰度**

	- **同步+回调的方式更直观**：
		- 业务代码只需在 `Channel` 里注册“可读回调”或“可写回调”，`epoll_wait` 一旦返回就绪，就按顺序调用对应回调，流程清晰。
		- 如果改为异步 IO，业务逻辑要分两步：先提交异步读取请求，再在某个完成事件里处理数据，整个流程会被拆分成“提交/完成”两个阶段，代码分散且难以维护。
	- **错误处理与资源回收更简单**：
		- 异步 IO 请求可能会在多次系统调用、不同时间点才完成，出错时需要在合适的回调里处理，也需要对应的超时检测。
		- 同步配合多路复用在 `HandleRead()`、`HandleWrite()` 里一步到位地“读/写 + 错误检查 + 关闭/重连”，业务逻辑更为集中。

4. **成熟度与社区生态**

	- 绝大多数开源网络库（如 muduo、libevent、libuv、Boost.Asio）都基于“同步 IO + 多路复用”或“同步 IO + 线程池”模型，且大量实战经验和优化都围绕着 epoll/IOCP 展开。
	- 如果使用异步 IO，需要自己完成大量底层封装、bug 验证以及边缘场景处理工作，而“同步+多路复用”已有丰富的最佳实践、文档和社区支持。

------

### 何时可以考虑使用异步 IO？

虽然大多数网络服务器选型会偏向“同步 + 多路复用” ，异步 IO 也值得尝试：

1. **磁盘 I/O 密集型场景**
	- 像数据库引擎、日志系统、大文件并发读写等，需要同时发起成百上千个并行磁盘 I/O，这时异步 IO（如 io_uring）能有效减少线程阻塞、提升吞吐。
2. **超高并发、大连接且进一步降延迟**
	- 当并发连接数上千万、单个 `epoll_wait` 本身的系统调用开销就成为瓶颈时，可以考虑使用 io_uring、IOCP 等真正的内核异步 IO，减少用户态与内核态之间的来回切换。
3. **特殊平台约束**
	- Windows 下若需要极限性能，可能直接用 IOCP；Linux 下若要做零拷贝、零系统调用的超高性能网络库，也可能借助 io_uring 的 `IORING_OP_READV`、`IORING_OP_WRITEV` 等。

但综合成本、可维护性和主流部署环境，**绝大多数网络应用依旧选择“同步 IO + 多路复用”** 作为主干架构。



### I/O 总结

- **IO 多路复用（select/poll/epoll）是同步 IO 的一种形式**：调用线程会阻塞在 `epoll_wait/ poll/ select`，直到内核检测到感兴趣的 FD 就绪，然后再同步地调用对应的读写操作。
- **同步 IO 与异步 IO 的区别**在于：
	- 同步 IO 里调用会一直“等”到本次操作可以进行（或超时／错误），读写在同一系统调用上下文中完成；
	- 异步 IO 里调用“异步提交”后立即返回，读写由内核后台执行，完成时会通知用户态，从而让线程不必一直阻塞等待。
- **项目中常用同步 + 多路复用而非异步 IO**，主要原因在于：
	1. 编程模型更直观、业务逻辑更集中；
	2. 兼容性和成熟度高，几乎所有主流系统/框架都已优化；
	3. 大多数网络 I/O 场景里，epoll + 同步读写即可满足高并发需求；
	4. 真正的异步 IO（io_uring、AIO、IOCP）在网络 I/O 下普及度不够，且集成成本和维护成本更高。

因此，除非对磁盘 I/O 或极限低延迟有特别需求，否则在网络服务器设计里仍以“同步 IO + 多路复用”作为主流方案。

### reactor、proactor模型的区别

1. Reactor 是**⾮阻塞同步**⽹络模式，感知的是**就绪可读写事件**。在每次感知到有事件发⽣（⽐如可读就绪事件）后，就需要应⽤进程主动调⽤ read ⽅法来完成数据的读取，也就是要应⽤进程主动将 socket 接收缓存中的数据读到应⽤进程内存中，这个过程是同步的，读取完数据后应⽤进程才能处理数据。
2.  Proactor 是**异步⽹络模式**， 感知的是**已完成的读写事件。**在发起异步读写请求时，需要传⼊数据缓冲区的地 址（⽤来存放结果数据）等信息，这样系统内核才可以⾃动帮我们把数据的读写⼯作完成，这⾥的读写⼯作全 程由操作系统来做，并不需要像 Reactor 那样还需要应⽤进程主动发起 read/write 来读写数据，操作系统完 成读写⼯作后，就会通知应⽤进程直接处理数据。

### reactor模式中，各个模式的区别？

Reactor模型是⼀个针对同步I/O的⽹络模型，主要是使⽤⼀个reactor负责监听和分配事件，将I/O事件分派给对应的Handler。新的事件包含连接建⽴就绪、读就绪、写就绪等。reactor模型中⼜可以细分为单reactor单线程、单reactor多线程、以及主从reactor模式。

1. **单reactor单线程模型**就是使⽤ I/O 多路复⽤技术，当其获取到活动的事件列表时，就在reactor中进⾏读取请 求、业务处理、返回响应，这样的好处是整个模型都使⽤⼀个线程，不存在资源的争夺问题。但是如果⼀个事 件的业务处理太过耗时，会导致后续所有的事件都得不到处理。
2. **单reactor多线程**就是⽤于解决这个问题，这个模型中reactor中只负责数据的接收和发送，reactor将业务处 理分给线程池中的线程进⾏处理，完成后将数据返回给reactor进⾏发送，避免了在reactor进⾏业务处理，但 是 IO 操作都在reactor中进⾏，容易存在性能问题。⽽且因为是多线程，线程池中每个线程完成业务后都需要 将结果传递给reactor进⾏发送，还会涉及到共享数据的互斥和保护机制。
3. **主从reactor**就是将reactor分为主reactor和从reactor，主reactor中只负责连接的建⽴和分配，读取请求、业务处理、返回响应等耗时的操作均在从reactor中处理，能够有效地应对⾼并发的场合。